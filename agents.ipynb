{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d2b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c803b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the WikipediaAPI which fetch our result with 200 characters\n",
    "wiki_api = WikipediaAPIWrapper(top_k_results = 1, doc_content_chars_max=200)\n",
    "#Make it as tool then our LLM can directly use it whenever it need\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper = wiki_api,\n",
    "                              name = \"wikipedia\",\n",
    "                              description=\"Search Wikipedia for factual information about general topics, such as countries, historical events, or public figures.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb832ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WikipediaQueryRun(description='Search Wikipedia for factual information about general topics, such as countries, historical events, or public figures.', api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Jasweer\\\\my_project\\\\Langchain\\\\Lvenv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a863f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Users\\jaswe\\AppData\\Local\\Temp\\ipykernel_21264\\2382940143.py:10: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  db = FAISS.from_documents(documents, OllamaEmbeddings(model = \"llama2\"))\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(web_path = \"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "db = FAISS.from_documents(documents, OllamaEmbeddings(model = \"llama2\"))\n",
    "retreiver = db.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d3935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retrieval_tool = create_retriever_tool(retreiver, \"langsmith_search\", \n",
    "\"Search for information about LangSmith. For any questions about LangSmith, you must use this tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e73a7921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "arxiv_api = ArxivAPIWrapper(top_k_results = 1, doc_content_chars_max = 200)\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper = arxiv_api,\n",
    "                           name=\"arxiv\",\n",
    "                            description=\"Search Arxiv for academic papers and research-related information.\")\n",
    "arxiv_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a011c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki_tool, arxiv_tool, retrieval_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b82453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model = \"llama2\", temperature=0, format = \"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19267563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], input_types={}, partial_variables={}, template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\n{tools}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or {tool_names}\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={}, template='{input}\\n\\n{agent_scratchpad}\\n (reminder to respond in a JSON blob no matter what)'), additional_kwargs={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb701731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_structured_chat_agent\n",
    "agent = create_structured_chat_agent(llm=llm, tools=tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd1d9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, \n",
    "                               tools=tools, \n",
    "                               verbose=True,\n",
    "                               handle_parsing_errors=True,\n",
    "                               max_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "251d2964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": {\"query\": \"OpenAI\"}}\u001b[0m\u001b[36;1m\u001b[1;3mPage: OpenAI\n",
      "Summary: OpenAI, Inc. is an American artificial intelligence (AI) organization headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general inte\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"arxiv\",\n",
      "  \"action_input\": {\"query\": \"OpenAI\"}}\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2016-06-05\n",
      "Title: OpenAI Gym\n",
      "Authors: Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, Wojciech Zaremba\n",
      "Summary: OpenAI Gym is a toolkit for reinfor\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"langsmith_search\",\n",
      "  \"action_input\": {\"query\": \"OpenAI\"}}\u001b[0m\u001b[38;5;200m\u001b[1;3mGet started with LangSmith - Docs by LangChainDocs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewQuickstartsTrace an applicationEvaluate an applicationTest promptsAPI & SDKsAPI referencePython SDKJS/TS SDKPricingPlansPricing FAQDocs by LangChain home pagePythonSearch...⌘KAsk AIGitHubForumForumSearch...NavigationGet started with LangSmithGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumGet started with LangSmithCopy pageCopy pageLangSmith is a platform for building production-grade LLM applications. Monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "LangSmith is framework agnostic — you can use it with or without LangChain’s open source frameworks langchain and langgraph.\n",
      "\n",
      "Start tracingGain visibility into each step your application takes when handling a request to debug faster.Learn moreEvaluate your applicationMeasure quality of your applications over time to build more reliable AI applications.Learn moreTest your promptsIterate on prompts, with automatic version control and collaboration features.Learn moreSet up your workspaceSet up your workspace, configure admin settings, and invite your team to collaborate.Learn moreTrace an applicationAssistantResponses are generated using AI and may contain mistakes.Docs by LangChain home pagegithubxlinkedinyoutubeResourcesChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"OpenAI is an American artificial intelligence organization headquartered in San Francisco, California. It aims to develop 'safe and beneficial' artificial general intelligence.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is OpenAI', 'output': \"OpenAI is an American artificial intelligence organization headquartered in San Francisco, California. It aims to develop 'safe and beneficial' artificial general intelligence.\"}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"What is OpenAI\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55071d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OpenAI is an American artificial intelligence organization headquartered in San Francisco, California. It aims to develop 'safe and beneficial' artificial general intelligence.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98c9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lvenv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
